# Guia de ConfiguraÃ§Ã£o - TYR CRM AI

## ğŸš€ InicializaÃ§Ã£o RÃ¡pida

### OpÃ§Ã£o 1: Docker Compose (Recomendado)

1. **Clone o repositÃ³rio e navegue atÃ© o diretÃ³rio:**
```bash
cd tyr-crm-ai
```

2. **Configure as variÃ¡veis de ambiente (opcional):**
```bash
# Backend - crie o arquivo .env
cd backend
cat > .env << EOF
# ConfiguraÃ§Ã£o do LLM
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3

# Ou use OpenAI:
# LLM_PROVIDER=openai
# OPENAI_API_KEY=sua-chave-aqui
EOF
cd ..
```

3. **Inicie todos os serviÃ§os:**
```bash
docker-compose up -d
```

4. **Acesse a aplicaÃ§Ã£o:**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Docs: http://localhost:8000/docs

5. **Ver logs:**
```bash
docker-compose logs -f
```

6. **Parar serviÃ§os:**
```bash
docker-compose down
```

### OpÃ§Ã£o 2: Desenvolvimento Local

#### Backend

1. **Navegue atÃ© o diretÃ³rio backend:**
```bash
cd backend
```

2. **Crie um ambiente virtual:**
```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

4. **Configure as variÃ¡veis de ambiente:**
```bash
cp .env.example .env
# Edite .env com suas configuraÃ§Ãµes
```

5. **Certifique-se de que o PostgreSQL estÃ¡ rodando:**
```bash
# Ou use Docker apenas para o banco:
docker run -d --name tyr-postgres \
  -e POSTGRES_USER=tyr_user \
  -e POSTGRES_PASSWORD=tyr_password \
  -e POSTGRES_DB=tyr_crm \
  -p 5432:5432 \
  postgres:15-alpine
```

6. **Inicie o servidor:**
```bash
uvicorn app.main:app --reload
```

#### Frontend

1. **Navegue atÃ© o diretÃ³rio frontend:**
```bash
cd frontend
```

2. **Instale as dependÃªncias:**
```bash
npm install
```

3. **Configure a URL da API (opcional):**
```bash
# Crie um arquivo .env.local
echo "VITE_API_URL=http://localhost:8000" > .env.local
```

4. **Inicie o servidor de desenvolvimento:**
```bash
npm run dev
```

## ğŸ“‹ Primeiros Passos

1. **Registre uma nova conta:**
   - Acesse http://localhost:3000/register
   - Preencha os dados (nome, email, senha, nome da empresa)
   - O sistema criarÃ¡ automaticamente um tenant para vocÃª

2. **FaÃ§a login:**
   - Acesse http://localhost:3000/login
   - Use as credenciais criadas

3. **Configure seu perfil (Opcional):**
   - Acesse /onboarding para configurar perfil da empresa, ICP e chaves de API

4. **Crie seu primeiro Playbook:**
   - Acesse /playbooks
   - Clique em "Criar Novo Playbook"
   - Preencha nome, descriÃ§Ã£o e conteÃºdo do playbook
   - O playbook serÃ¡ usado pelo agente SDR para gerar sugestÃµes

5. **Teste o Agente:**
   - Use a API para processar um lead
   - POST /api/agents/process-lead
   - O agente pesquisarÃ¡ sobre o lead e sugerirÃ¡ uma abordagem

## ğŸ”§ ConfiguraÃ§Ã£o AvanÃ§ada

### VariÃ¡veis de Ambiente do Backend

- `DATABASE_URL`: URL de conexÃ£o do PostgreSQL
- `SECRET_KEY`: Chave secreta para JWT (mude em produÃ§Ã£o!)
- `ALGORITHM`: Algoritmo JWT (padrÃ£o: HS256)
- `ACCESS_TOKEN_EXPIRE_MINUTES`: Tempo de expiraÃ§Ã£o do token (padrÃ£o: 30)
- `OPENAI_API_KEY`: Chave da API OpenAI (opcional, para IA real)
- `LLM_PROVIDER`: Provedor de LLM - "openai" ou "ollama" (padrÃ£o: "openai")
- `OLLAMA_BASE_URL`: URL base do Ollama (padrÃ£o: "http://localhost:11434")
  - **Em ambiente Docker**: Use `http://host.docker.internal:11434` se o Ollama estiver rodando no host
  - **Em ambiente local**: Use `http://localhost:11434`
- `OLLAMA_MODEL`: Modelo do Ollama a ser usado (padrÃ£o: "llama3")

### VariÃ¡veis de Ambiente do Frontend

- `VITE_API_URL`: URL da API backend (padrÃ£o: http://localhost:8000)

## ğŸ› Troubleshooting

### Erro de conexÃ£o com o banco de dados
- Verifique se o PostgreSQL estÃ¡ rodando
- Confirme as credenciais no arquivo .env
- Verifique se a porta 5432 estÃ¡ disponÃ­vel

### Erro ao iniciar o frontend
- Certifique-se de que o Node.js 18+ estÃ¡ instalado
- Delete node_modules e reinstale: `rm -rf node_modules && npm install`

### Erro ao iniciar o backend
- Verifique se o Python 3.11+ estÃ¡ instalado
- Certifique-se de que todas as dependÃªncias foram instaladas
- Verifique se o banco de dados estÃ¡ acessÃ­vel

### Erro "Connection refused" ao processar PDF do LinkedIn
Este erro ocorre quando o sistema tenta usar o Ollama mas nÃ£o consegue se conectar. SoluÃ§Ãµes:

**OpÃ§Ã£o 1: Usar OpenAI (Recomendado para produÃ§Ã£o)**
```bash
# No arquivo backend/.env
LLM_PROVIDER=openai
OPENAI_API_KEY=sua-chave-aqui
```

**OpÃ§Ã£o 2: Configurar Ollama em Docker (RECOMENDADO - jÃ¡ configurado por padrÃ£o)**
1. Certifique-se de que o Ollama estÃ¡ rodando no seu computador (nÃ£o dentro do container)
2. Crie o arquivo `backend/.env` com:
```bash
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://host.docker.internal:11434
OLLAMA_MODEL=llama3
```

**Nota**: O `docker-compose.yml` jÃ¡ estÃ¡ configurado para usar `host.docker.internal:11434` por padrÃ£o. VocÃª sÃ³ precisa criar o arquivo `.env` se quiser sobrescrever essas configuraÃ§Ãµes.

**OpÃ§Ã£o 3: Rodar Ollama em Docker tambÃ©m**
Adicione ao `docker-compose.yml`:
```yaml
  ollama:
    image: ollama/ollama:latest
    container_name: tyr-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
```

E configure no `backend/.env`:
```bash
LLM_PROVIDER=ollama
OLLAMA_BASE_URL=http://ollama:11434
OLLAMA_MODEL=llama3
```

**Nota**: Se usar a OpÃ§Ã£o 3, adicione `ollama` aos `depends_on` do serviÃ§o `backend` no docker-compose.yml

## ğŸ“š Estrutura do Projeto

```
tyr-crm-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/          # Agentes LangGraph
â”‚   â”‚   â”œâ”€â”€ routers/         # Rotas da API
â”‚   â”‚   â”œâ”€â”€ models.py        # Modelos SQLModel
â”‚   â”‚   â”œâ”€â”€ auth.py          # AutenticaÃ§Ã£o JWT
â”‚   â”‚   â””â”€â”€ main.py          # AplicaÃ§Ã£o FastAPI
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # Componentes React
â”‚   â”‚   â”œâ”€â”€ pages/           # PÃ¡ginas
â”‚   â”‚   â”œâ”€â”€ contexts/        # Contextos (Auth, Theme)
â”‚   â”‚   â”œâ”€â”€ i18n/            # InternacionalizaÃ§Ã£o
â”‚   â”‚   â””â”€â”€ lib/             # UtilitÃ¡rios
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## ğŸ” SeguranÃ§a

âš ï¸ **IMPORTANTE**: Em produÃ§Ã£o:
- Altere o `SECRET_KEY` para um valor seguro e aleatÃ³rio
- Use variÃ¡veis de ambiente para todas as credenciais
- Configure HTTPS
- Implemente rate limiting
- Adicione validaÃ§Ã£o de entrada mais rigorosa
- Configure CORS adequadamente

## ğŸ“ Notas

- O agente SDR funciona sem OpenAI API key, mas retornarÃ¡ respostas simuladas
- Para usar IA real, configure a `OPENAI_API_KEY` no backend
- O sistema suporta multi-tenancy: cada usuÃ¡rio sÃ³ vÃª dados do seu tenant
- Todos os dados sÃ£o isolados por `tenant_id`

