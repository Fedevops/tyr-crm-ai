"""
Utilit√°rios para processamento de PDFs do LinkedIn
"""
import logging
import json
import io
from typing import Dict, Any, Optional
from fastapi import UploadFile
from sqlmodel import Session
import pdfplumber
from app.agents.llm_helper import get_llm, is_llm_available, extract_token_usage
from app.services.token_tracker import track_llm_tokens
from app.config import settings

logger = logging.getLogger(__name__)


async def extract_text_from_pdf(pdf_file: UploadFile) -> str:
    """
    Extrai texto de um arquivo PDF
    
    Args:
        pdf_file: Arquivo PDF enviado via upload
        
    Returns:
        String com todo o texto extra√≠do do PDF
        
    Raises:
        ValueError: Se o PDF estiver corrompido ou inv√°lido
    """
    try:
        # Ler conte√∫do do arquivo
        contents = await pdf_file.read()
        
        # Criar objeto BytesIO para pdfplumber
        pdf_bytes = io.BytesIO(contents)
        
        # Extrair texto de todas as p√°ginas
        full_text = ""
        with pdfplumber.open(pdf_bytes) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    full_text += page_text + "\n"
        
        if not full_text.strip():
            raise ValueError("PDF n√£o cont√©m texto extra√≠vel. Pode ser um PDF escaneado (imagem).")
        
        logger.info(f"‚úÖ [PDF PARSER] Texto extra√≠do: {len(full_text)} caracteres")
        return full_text
        
    except pdfplumber.exceptions.PDFSyntaxError as e:
        logger.error(f"‚ùå [PDF PARSER] Erro de sintaxe no PDF: {e}")
        raise ValueError(f"PDF inv√°lido ou corrompido: {str(e)}")
    except Exception as e:
        logger.error(f"‚ùå [PDF PARSER] Erro ao extrair texto do PDF: {e}")
        raise ValueError(f"Erro ao processar PDF: {str(e)}")


async def parse_linkedin_data_with_llm(text: str, session: Session, tenant_id: int, user_id: Optional[int] = None) -> Dict[str, Any]:
    """
    Usa LLM para analisar texto extra√≠do de PDF do LinkedIn e extrair dados estruturados
    
    Args:
        text: Texto extra√≠do do PDF
        
    Returns:
        Dicion√°rio com dados estruturados do LinkedIn
        
    Raises:
        ValueError: Se LLM n√£o estiver dispon√≠vel ou houver erro na an√°lise
    """
    if not is_llm_available():
        raise ValueError("LLM n√£o est√° configurado. Configure OpenAI, Ollama ou DeepSeek no arquivo .env")
    
    llm = get_llm(temperature=0.2)  # Baixa temperatura para extra√ß√£o precisa
    
    if not llm:
        raise ValueError("N√£o foi poss√≠vel inicializar o LLM. Verifique as configura√ß√µes.")
    
    prompt = f"""Voc√™ √© um assistente especializado em extrair informa√ß√µes estruturadas de perfis do LinkedIn exportados em PDF.

Analise o seguinte texto extra√≠do de um PDF do LinkedIn e extraia as informa√ß√µes relevantes. Retorne APENAS um JSON v√°lido, sem texto adicional antes ou depois.

Texto do PDF:
---
{text}
---

Extraia as seguintes informa√ß√µes e retorne em formato JSON:

{{
  "linkedin_headline": "T√≠tulo profissional/headline (ex: 'Especialista Backend | 10+ anos | Python, Django, FastAPI')",
  "linkedin_about": "Texto completo do campo 'Sobre' ou resumo profissional",
  "linkedin_experience_json": [
    {{
      "position": "Cargo/Posi√ß√£o",
      "company": "Nome da empresa",
      "start_date": "Data de in√≠cio (formato: YYYY-MM ou YYYY)",
      "end_date": "Data de t√©rmino (formato: YYYY-MM ou YYYY, ou null se atual)",
      "description": "Descri√ß√£o das responsabilidades e conquistas"
    }}
  ],
  "linkedin_education_json": [
    {{
      "institution": "Nome da institui√ß√£o",
      "degree": "Grau obtido (ex: 'Bacharelado', 'Mestrado')",
      "field": "√Årea de estudo",
      "start_date": "Ano de in√≠cio (YYYY)",
      "end_date": "Ano de conclus√£o (YYYY ou null se n√£o conclu√≠do)"
    }}
  ],
  "linkedin_certifications_json": [
    {{
      "name": "Nome da certifica√ß√£o",
      "issuer": "Organiza√ß√£o emissora",
      "issue_date": "Data de emiss√£o (formato: YYYY-MM ou YYYY)",
      "expiration_date": "Data de expira√ß√£o (formato: YYYY-MM ou YYYY, ou null se n√£o expira)",
      "credential_id": "ID da credencial (se dispon√≠vel)"
    }}
  ],
  "linkedin_skills": "Lista de habilidades separadas por v√≠rgula (ex: 'Python, Django, FastAPI, PostgreSQL, AWS')",
  "linkedin_articles_json": [
    {{
      "title": "T√≠tulo do artigo",
      "published_date": "Data de publica√ß√£o (formato: YYYY-MM ou YYYY)",
      "url": "URL do artigo (se dispon√≠vel)",
      "description": "Breve descri√ß√£o (se dispon√≠vel)"
    }}
  ],
  "linkedin_connections_count": n√∫mero de conex√µes (se mencionado, sen√£o null),
  "linkedin_followers_count": n√∫mero de seguidores (se mencionado, sen√£o null)
}}

IMPORTANTE:
- Retorne APENAS o JSON, sem markdown, sem c√≥digo, sem explica√ß√µes
- Se alguma informa√ß√£o n√£o estiver dispon√≠vel, use null
- Para arrays vazios, retorne []
- Para strings vazias, use ""
- Mantenha o formato de datas consistente
- linkedin_skills deve ser uma string √∫nica separada por v√≠rgula, n√£o um array
"""

    try:
        logger.info("ü§ñ [PDF PARSER] Enviando texto para LLM para an√°lise...")
        response = llm.invoke(prompt)
        
        # Rastrear uso de tokens
        try:
            provider = settings.llm_provider.lower()
            model = settings.openai_model if provider == "openai" else settings.ollama_model
            token_info = extract_token_usage(response, provider)
            # Estimar prompt_tokens se n√£o dispon√≠vel (para Ollama)
            if token_info['prompt_tokens'] == 0 and token_info['total_tokens'] > 0:
                estimated_prompt = int(token_info['total_tokens'] * 0.7)
                token_info['prompt_tokens'] = estimated_prompt
                token_info['completion_tokens'] = token_info['total_tokens'] - estimated_prompt
            track_llm_tokens(
                session=session,
                tenant_id=tenant_id,
                user_id=user_id,
                provider=provider,
                model=model,
                prompt_tokens=token_info['prompt_tokens'],
                completion_tokens=token_info['completion_tokens'],
                total_tokens=token_info['total_tokens'],
                endpoint="/api/leads/parse-linkedin-pdf",
                feature="pdf_parsing"
            )
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao rastrear tokens: {e}")
        
        # Extrair conte√∫do da resposta
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        # Limpar resposta (remover markdown code blocks se houver)
        response_text = response_text.strip()
        if response_text.startswith("```json"):
            response_text = response_text[7:]
        elif response_text.startswith("```"):
            response_text = response_text[3:]
        if response_text.endswith("```"):
            response_text = response_text[:-3]
        response_text = response_text.strip()
        
        # Parsear JSON
        try:
            parsed_data = json.loads(response_text)
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå [PDF PARSER] Erro ao parsear JSON da resposta do LLM: {e}")
            logger.error(f"‚ùå [PDF PARSER] Resposta recebida: {response_text[:500]}")
            raise ValueError(f"Resposta do LLM n√£o √© um JSON v√°lido: {str(e)}")
        
        # Validar e normalizar dados
        normalized_data = {
            "linkedin_headline": parsed_data.get("linkedin_headline") or None,
            "linkedin_about": parsed_data.get("linkedin_about") or None,
            "linkedin_experience_json": json.dumps(parsed_data.get("linkedin_experience_json", []), ensure_ascii=False) if parsed_data.get("linkedin_experience_json") else None,
            "linkedin_education_json": json.dumps(parsed_data.get("linkedin_education_json", []), ensure_ascii=False) if parsed_data.get("linkedin_education_json") else None,
            "linkedin_certifications_json": json.dumps(parsed_data.get("linkedin_certifications_json", []), ensure_ascii=False) if parsed_data.get("linkedin_certifications_json") else None,
            "linkedin_skills": parsed_data.get("linkedin_skills") or None,
            "linkedin_articles_json": json.dumps(parsed_data.get("linkedin_articles_json", []), ensure_ascii=False) if parsed_data.get("linkedin_articles_json") else None,
            "linkedin_connections_count": parsed_data.get("linkedin_connections_count") if isinstance(parsed_data.get("linkedin_connections_count"), int) else None,
            "linkedin_followers_count": parsed_data.get("linkedin_followers_count") if isinstance(parsed_data.get("linkedin_followers_count"), int) else None,
        }
        
        # Remover campos None
        normalized_data = {k: v for k, v in normalized_data.items() if v is not None}
        
        logger.info(f"‚úÖ [PDF PARSER] Dados extra√≠dos: {list(normalized_data.keys())}")
        return normalized_data
        
    except ValueError:
        raise
    except ConnectionError as e:
        logger.error(f"‚ùå [PDF PARSER] Erro de conex√£o com LLM: {e}")
        raise ValueError(f"Erro de conex√£o com LLM: {str(e)}")
    except Exception as e:
        logger.error(f"‚ùå [PDF PARSER] Erro ao processar com LLM: {e}")
        raise ValueError(f"Erro ao analisar PDF com LLM: {str(e)}")

