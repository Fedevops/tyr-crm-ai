"""
Utilit√°rios para processamento de PDFs do LinkedIn
"""
import logging
import json
import io
from typing import Dict, Any, Optional
from fastapi import UploadFile
from sqlmodel import Session
import pdfplumber
from app.agents.llm_helper import get_llm, is_llm_available, extract_token_usage
from app.services.token_tracker import track_llm_tokens
from app.config import settings

logger = logging.getLogger(__name__)


async def extract_text_from_pdf(pdf_file: UploadFile) -> str:
    """
    Extrai texto de um arquivo PDF
    
    Args:
        pdf_file: Arquivo PDF enviado via upload
        
    Returns:
        String com todo o texto extra√≠do do PDF
        
    Raises:
        ValueError: Se o PDF estiver corrompido ou inv√°lido
    """
    try:
        # Ler conte√∫do do arquivo
        contents = await pdf_file.read()
        
        # Criar objeto BytesIO para pdfplumber
        pdf_bytes = io.BytesIO(contents)
        
        # Extrair texto de todas as p√°ginas
        full_text = ""
        with pdfplumber.open(pdf_bytes) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    full_text += page_text + "\n"
        
        if not full_text.strip():
            raise ValueError("PDF n√£o cont√©m texto extra√≠vel. Pode ser um PDF escaneado (imagem).")
        
        logger.info(f"‚úÖ [PDF PARSER] Texto extra√≠do: {len(full_text)} caracteres")
        return full_text
        
    except pdfplumber.exceptions.PDFSyntaxError as e:
        logger.error(f"‚ùå [PDF PARSER] Erro de sintaxe no PDF: {e}")
        raise ValueError(f"PDF inv√°lido ou corrompido: {str(e)}")
    except Exception as e:
        logger.error(f"‚ùå [PDF PARSER] Erro ao extrair texto do PDF: {e}")
        raise ValueError(f"Erro ao processar PDF: {str(e)}")


async def parse_linkedin_data_with_llm(text: str, session: Session, tenant_id: int, user_id: Optional[int] = None) -> Dict[str, Any]:
    """
    Usa LLM para analisar texto extra√≠do de PDF do LinkedIn e extrair dados estruturados
    
    Args:
        text: Texto extra√≠do do PDF
        
    Returns:
        Dicion√°rio com dados estruturados do LinkedIn
        
    Raises:
        ValueError: Se LLM n√£o estiver dispon√≠vel ou houver erro na an√°lise
    """
    if not is_llm_available():
        raise ValueError("LLM n√£o est√° configurado. Configure OpenAI, Ollama ou DeepSeek no arquivo .env")
    
    llm = get_llm(temperature=0.2)  # Baixa temperatura para extra√ß√£o precisa
    
    if not llm:
        raise ValueError("N√£o foi poss√≠vel inicializar o LLM. Verifique as configura√ß√µes.")
    
    prompt = f"""Voc√™ √© um assistente especializado em extrair informa√ß√µes estruturadas de perfis do LinkedIn exportados em PDF.

Analise o seguinte texto extra√≠do de um PDF do LinkedIn e extraia as informa√ß√µes relevantes. Retorne APENAS um JSON v√°lido, sem texto adicional antes ou depois.

Texto do PDF:
---
{text}
---

Extraia as seguintes informa√ß√µes e retorne em formato JSON:

{{
  "name": "Nome completo da pessoa (obrigat√≥rio se dispon√≠vel)",
  "email": "Email de contato (se mencionado no PDF)",
  "phone": "Telefone de contato (se mencionado no PDF, apenas n√∫meros e + se internacional)",
  "company": "Nome da empresa ATUAL onde a pessoa trabalha (OBRIGAT√ìRIO extrair da experi√™ncia mais recente ou do headline se n√£o houver experi√™ncia expl√≠cita). Se n√£o houver empresa atual, usar a mais recente. NUNCA deixe null se houver qualquer informa√ß√£o sobre empresa no texto.",
  "position": "Cargo/posi√ß√£o ATUAL da pessoa (OBRIGAT√ìRIO extrair da experi√™ncia mais recente ou do headline). Exemplos: 'Desenvolvedor Backend', 'Gerente de Vendas', 'CEO', 'Diretor de Marketing', etc. NUNCA deixe null se houver qualquer informa√ß√£o sobre cargo no texto.",
  "industry": "Setor/Ind√∫stria da empresa atual (ex: 'Tecnologia da Informa√ß√£o', 'Varejo', 'Sa√∫de', 'Servi√ßos Financeiros', 'Consultoria', 'Manufatura', 'Educa√ß√£o', 'Telecomunica√ß√µes', etc.). Se n√£o estiver expl√≠cito, INFERIR baseado no nome da empresa, tipo de cargo ou descri√ß√£o da empresa. Exemplos: se a empresa √© 'Microsoft' ou 'Google', industry √© 'Tecnologia da Informa√ß√£o'. Se o cargo √© 'M√©dico' ou 'Enfermeiro', industry pode ser 'Sa√∫de'.",
  "website": "Website pessoal ou da empresa (se mencionado)",
  "linkedin_url": "URL do perfil do LinkedIn (se mencionado)",
  "linkedin_headline": "T√≠tulo profissional/headline (ex: 'Especialista Backend | 10+ anos | Python, Django, FastAPI')",
  "linkedin_about": "Texto completo do campo 'Sobre' ou resumo profissional",
  "linkedin_experience_json": [
    {{
      "position": "Cargo/Posi√ß√£o",
      "company": "Nome da empresa",
      "start_date": "Data de in√≠cio (formato: YYYY-MM ou YYYY)",
      "end_date": "Data de t√©rmino (formato: YYYY-MM ou YYYY, ou null se atual)",
      "description": "Descri√ß√£o das responsabilidades e conquistas"
    }}
  ],
  "linkedin_education_json": [
    {{
      "institution": "Nome da institui√ß√£o",
      "degree": "Grau obtido (ex: 'Bacharelado', 'Mestrado')",
      "field": "√Årea de estudo",
      "start_date": "Ano de in√≠cio (YYYY)",
      "end_date": "Ano de conclus√£o (YYYY ou null se n√£o conclu√≠do)"
    }}
  ],
  "linkedin_certifications_json": [
    {{
      "name": "Nome da certifica√ß√£o",
      "issuer": "Organiza√ß√£o emissora",
      "issue_date": "Data de emiss√£o (formato: YYYY-MM ou YYYY)",
      "expiration_date": "Data de expira√ß√£o (formato: YYYY-MM ou YYYY, ou null se n√£o expira)",
      "credential_id": "ID da credencial (se dispon√≠vel)"
    }}
  ],
  "linkedin_skills": "Lista de habilidades separadas por v√≠rgula (ex: 'Python, Django, FastAPI, PostgreSQL, AWS')",
  "linkedin_articles_json": [
    {{
      "title": "T√≠tulo do artigo",
      "published_date": "Data de publica√ß√£o (formato: YYYY-MM ou YYYY)",
      "url": "URL do artigo (se dispon√≠vel)",
      "description": "Breve descri√ß√£o (se dispon√≠vel)"
    }}
  ],
  "linkedin_connections_count": n√∫mero de conex√µes (se mencionado, sen√£o null),
  "linkedin_followers_count": n√∫mero de seguidores (se mencionado, sen√£o null)
}}

INSTRU√á√ïES CR√çTICAS:
- Retorne APENAS o JSON v√°lido, sem markdown, sem c√≥digo, sem explica√ß√µes, sem texto antes ou depois
- N√ÉO use markdown code blocks (```json ou ```)
- N√ÉO adicione coment√°rios ou explica√ß√µes
- Se alguma informa√ß√£o n√£o estiver dispon√≠vel, use null (n√£o use undefined, n√£o deixe campos faltando)
- Para arrays vazios, retorne [] (array vazio, n√£o null)
- Para strings vazias, use "" (string vazia, n√£o null)
- Mantenha o formato de datas consistente
- linkedin_skills deve ser uma string √∫nica separada por v√≠rgula, n√£o um array
- ESCAPE corretamente todas as aspas dentro de strings usando \"
- N√ÉO use v√≠rgulas finais antes de fechar objetos ou arrays
- Certifique-se de que todos os n√∫meros est√£o sem aspas (exceto se forem parte de uma string)
- Certifique-se de que todos os valores null est√£o em min√∫sculas (null, n√£o NULL ou None)

EXTRA√á√ÉO DE EMPRESA E CARGO:
- Para "company": SEMPRE extrair da experi√™ncia mais recente (atual) se dispon√≠vel. Se n√£o houver experi√™ncia expl√≠cita, extrair do headline ou do texto do perfil. NUNCA deixe null se houver qualquer men√ß√£o a empresa no texto.
- Para "position": SEMPRE extrair da experi√™ncia mais recente (atual) se dispon√≠vel. Se n√£o houver experi√™ncia expl√≠cita, extrair do headline. NUNCA deixe null se houver qualquer men√ß√£o a cargo/posi√ß√£o no texto.
- Se a pessoa tiver m√∫ltiplas experi√™ncias, priorizar SEMPRE a mais recente (atual) para company e position
- Exemplos de position: "Desenvolvedor Backend", "Gerente de Vendas", "CEO", "Diretor de Marketing", "Analista de Dados", etc.

EXTRA√á√ÉO DE SEGMENTO/INDUSTRIA:
- Para "industry": Tentar identificar o setor/ind√∫stria da empresa atual
- Se estiver expl√≠cito no texto, usar exatamente como est√°
- Se n√£o estiver expl√≠cito, INFERIR baseado em:
  * Nome da empresa (ex: "Microsoft" ‚Üí "Tecnologia da Informa√ß√£o", "Hospital X" ‚Üí "Sa√∫de")
  * Tipo de cargo (ex: "M√©dico" ‚Üí "Sa√∫de", "Engenheiro de Software" ‚Üí "Tecnologia da Informa√ß√£o")
  * Descri√ß√£o da empresa ou cargo
- Exemplos de industry: "Tecnologia da Informa√ß√£o", "Varejo", "Sa√∫de", "Servi√ßos Financeiros", "Consultoria", "Manufatura", "Educa√ß√£o", "Telecomunica√ß√µes", "Constru√ß√£o Civil", "Alimenta√ß√£o", etc.
- Se realmente n√£o conseguir inferir, use null
"""

    try:
        logger.info("ü§ñ [PDF PARSER] Enviando texto para LLM para an√°lise...")
        response = llm.invoke(prompt)
        
        # Rastrear uso de tokens
        try:
            provider = settings.llm_provider.lower()
            model = settings.openai_model if provider == "openai" else settings.ollama_model
            token_info = extract_token_usage(response, provider)
            # Estimar prompt_tokens se n√£o dispon√≠vel (para Ollama)
            if token_info['prompt_tokens'] == 0 and token_info['total_tokens'] > 0:
                estimated_prompt = int(token_info['total_tokens'] * 0.7)
                token_info['prompt_tokens'] = estimated_prompt
                token_info['completion_tokens'] = token_info['total_tokens'] - estimated_prompt
            track_llm_tokens(
                session=session,
                tenant_id=tenant_id,
                user_id=user_id,
                provider=provider,
                model=model,
                prompt_tokens=token_info['prompt_tokens'],
                completion_tokens=token_info['completion_tokens'],
                total_tokens=token_info['total_tokens'],
                endpoint="/api/leads/parse-linkedin-pdf",
                feature="pdf_parsing"
            )
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Erro ao rastrear tokens: {e}")
        
        # Extrair conte√∫do da resposta
        response_text = response.content if hasattr(response, 'content') else str(response)
        
        # Limpar resposta (remover markdown code blocks se houver)
        response_text = response_text.strip()
        if response_text.startswith("```json"):
            response_text = response_text[7:]
        elif response_text.startswith("```"):
            response_text = response_text[3:]
        if response_text.endswith("```"):
            response_text = response_text[:-3]
        response_text = response_text.strip()
        
        # Tentar extrair JSON se houver texto antes/depois
        import re
        json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
        if json_match:
            response_text = json_match.group(0)
        
        # Tentar corrigir problemas comuns de JSON
        # Remover v√≠rgulas finais antes de fechar objetos/arrays
        response_text = re.sub(r',\s*}', '}', response_text)
        response_text = re.sub(r',\s*]', ']', response_text)
        
        # Parsear JSON
        parsed_data = None
        json_error = None
        try:
            parsed_data = json.loads(response_text)
        except json.JSONDecodeError as e:
            json_error = e
            logger.warning(f"‚ö†Ô∏è [PDF PARSER] Primeira tentativa de parse JSON falhou: {e}")
            logger.warning(f"‚ö†Ô∏è [PDF PARSER] Posi√ß√£o do erro: linha {e.lineno}, coluna {e.colno}")
            
            # Tentar corrigir problemas comuns
            try:
                # Tentar escapar caracteres de controle e quebras de linha problem√°ticas
                fixed_text = response_text
                # Remover caracteres de controle exceto \n, \r, \t
                fixed_text = ''.join(char for char in fixed_text if ord(char) >= 32 or char in '\n\r\t')
                
                # Tentar encontrar e extrair apenas o JSON v√°lido
                # Procurar pelo primeiro { e √∫ltimo }
                first_brace = fixed_text.find('{')
                last_brace = fixed_text.rfind('}')
                if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
                    fixed_text = fixed_text[first_brace:last_brace + 1]
                
                # Tentar corrigir problemas comuns de JSON
                # 1. Remover v√≠rgulas finais
                fixed_text = re.sub(r',\s*}', '}', fixed_text)
                fixed_text = re.sub(r',\s*]', ']', fixed_text)
                
                # 2. Tentar corrigir aspas simples n√£o escapadas (substituir por aspas duplas escapadas)
                # Mas apenas dentro de strings JSON (isso √© complexo, ent√£o vamos ser conservadores)
                
                # 3. Tentar corrigir quebras de linha dentro de strings JSON
                # Substituir \n por \\n dentro de strings (mas isso √© muito complexo sem parser)
                
                # 4. Tentar corrigir valores undefined/None para null
                fixed_text = re.sub(r'\bundefined\b', 'null', fixed_text)
                fixed_text = re.sub(r'\bNone\b', 'null', fixed_text)
                fixed_text = re.sub(r'\bNULL\b', 'null', fixed_text)
                
                # Tentar parsear novamente
                parsed_data = json.loads(fixed_text)
                logger.info("‚úÖ [PDF PARSER] JSON corrigido com sucesso na segunda tentativa")
            except (json.JSONDecodeError, Exception) as e2:
                logger.error(f"‚ùå [PDF PARSER] Erro ao parsear JSON mesmo ap√≥s corre√ß√£o: {e2}")
                logger.error(f"‚ùå [PDF PARSER] Resposta original (primeiros 1000 chars): {response_text[:1000]}")
                logger.error(f"‚ùå [PDF PARSER] Resposta original (√∫ltimos 500 chars): {response_text[-500:]}")
                
                # Tentar uma √∫ltima vez com uma abordagem mais agressiva: usar json5 ou tentar reparar manualmente
                try:
                    # Tentar usar uma biblioteca de reparo de JSON se dispon√≠vel
                    try:
                        import json5
                        parsed_data = json5.loads(response_text)
                        logger.info("‚úÖ [PDF PARSER] JSON reparado usando json5")
                    except ImportError:
                        # json5 n√£o dispon√≠vel, tentar uma √∫ltima corre√ß√£o manual
                        # Remover tudo que n√£o seja JSON v√°lido
                        lines = response_text.split('\n')
                        json_lines = []
                        in_json = False
                        brace_count = 0
                        for line in lines:
                            if '{' in line:
                                in_json = True
                            if in_json:
                                json_lines.append(line)
                                brace_count += line.count('{') - line.count('}')
                                if brace_count == 0 and '}' in line:
                                    break
                        
                        if json_lines:
                            fixed_text = '\n'.join(json_lines)
                            # Aplicar todas as corre√ß√µes novamente
                            fixed_text = re.sub(r',\s*}', '}', fixed_text)
                            fixed_text = re.sub(r',\s*]', ']', fixed_text)
                            fixed_text = re.sub(r'\bundefined\b', 'null', fixed_text)
                            fixed_text = re.sub(r'\bNone\b', 'null', fixed_text)
                            fixed_text = re.sub(r'\bNULL\b', 'null', fixed_text)
                            parsed_data = json.loads(fixed_text)
                            logger.info("‚úÖ [PDF PARSER] JSON reparado manualmente na terceira tentativa")
                        else:
                            raise ValueError("N√£o foi poss√≠vel extrair JSON v√°lido")
                except Exception as e3:
                    logger.error(f"‚ùå [PDF PARSER] Todas as tentativas de reparo falharam: {e3}")
                    if json_error:
                        error_msg = f"Resposta do LLM n√£o √© um JSON v√°lido: {str(json_error)}. Posi√ß√£o do erro: linha {json_error.lineno}, coluna {json_error.colno}"
                        # Adicionar contexto do erro
                        if json_error.lineno and json_error.colno:
                            lines = response_text.split('\n')
                            if json_error.lineno <= len(lines):
                                error_line = lines[json_error.lineno - 1]
                                error_msg += f"\nLinha com erro: {error_line[:200]}"
                                if json_error.colno:
                                    error_msg += f"\nPosi√ß√£o: {' ' * min(json_error.colno - 1, 50)}^"
                        raise ValueError(error_msg)
                    raise ValueError(f"Resposta do LLM n√£o √© um JSON v√°lido: {str(e2)}")
        
        if parsed_data is None:
            raise ValueError("N√£o foi poss√≠vel parsear a resposta do LLM como JSON")
        
        # Validar e normalizar dados
        normalized_data = {
            "name": parsed_data.get("name") or None,
            "email": parsed_data.get("email") or None,
            "phone": parsed_data.get("phone") or None,
            "company": parsed_data.get("company") or None,
            "position": parsed_data.get("position") or None,
            "industry": parsed_data.get("industry") or None,
            "website": parsed_data.get("website") or None,
            "linkedin_url": parsed_data.get("linkedin_url") or None,
            "linkedin_headline": parsed_data.get("linkedin_headline") or None,
            "linkedin_about": parsed_data.get("linkedin_about") or None,
            "linkedin_experience_json": json.dumps(parsed_data.get("linkedin_experience_json", []), ensure_ascii=False) if parsed_data.get("linkedin_experience_json") else None,
            "linkedin_education_json": json.dumps(parsed_data.get("linkedin_education_json", []), ensure_ascii=False) if parsed_data.get("linkedin_education_json") else None,
            "linkedin_certifications_json": json.dumps(parsed_data.get("linkedin_certifications_json", []), ensure_ascii=False) if parsed_data.get("linkedin_certifications_json") else None,
            "linkedin_skills": parsed_data.get("linkedin_skills") or None,
            "linkedin_articles_json": json.dumps(parsed_data.get("linkedin_articles_json", []), ensure_ascii=False) if parsed_data.get("linkedin_articles_json") else None,
            "linkedin_connections_count": parsed_data.get("linkedin_connections_count") if isinstance(parsed_data.get("linkedin_connections_count"), int) else None,
            "linkedin_followers_count": parsed_data.get("linkedin_followers_count") if isinstance(parsed_data.get("linkedin_followers_count"), int) else None,
        }
        
        # Remover campos None
        normalized_data = {k: v for k, v in normalized_data.items() if v is not None}
        
        logger.info(f"‚úÖ [PDF PARSER] Dados extra√≠dos: {list(normalized_data.keys())}")
        return normalized_data
        
    except ValueError:
        raise
    except ConnectionError as e:
        logger.error(f"‚ùå [PDF PARSER] Erro de conex√£o com LLM: {e}")
        raise ValueError(f"Erro de conex√£o com LLM: {str(e)}")
    except Exception as e:
        logger.error(f"‚ùå [PDF PARSER] Erro ao processar com LLM: {e}")
        raise ValueError(f"Erro ao analisar PDF com LLM: {str(e)}")

